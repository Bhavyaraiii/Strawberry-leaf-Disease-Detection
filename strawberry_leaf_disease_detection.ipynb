{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4WhXsyhNAZs",
        "outputId": "34df6736-5e03-46aa-e51c-35dce58e7b9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoShjHwoQQmU",
        "outputId": "e2bbf674-dfdb-4fbf-ec39-6473322ccb1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEVR6gkWQTvX",
        "outputId": "7fce4bfc-4e81-47c0-8a7b-65aa20c7a30f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2026.1.4)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLGqeBoNQdTq",
        "outputId": "a56763fc-bcbe-49f8-b044-3c20cdb9607e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/cli.py\", line 68, in main\n",
            "    out = args.func(**command_args)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 1741, in dataset_download_cli\n",
            "    with self.build_kaggle_client() as kaggle:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 688, in build_kaggle_client\n",
            "    username=self.config_values['username'],\n",
            "             ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "KeyError: 'username'\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d ercanavsar/images-of-strawberry-leaves-for-tipburn-detection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDfww0EWXVKS",
        "outputId": "00b114b1-b014-46ac-c0cd-dab5eeebfcb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "id": "8eZU1If5Xm5H",
        "outputId": "d9c3e382-6c26-4342-96d3-199261c3e765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2026.1.4)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/cli.py\", line 68, in main\n",
            "    out = args.func(**command_args)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 1741, in dataset_download_cli\n",
            "    with self.build_kaggle_client() as kaggle:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 688, in build_kaggle_client\n",
            "    username=self.config_values['username'],\n",
            "             ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "KeyError: 'username'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/images-of-strawberry-leaves-for-tipburn-detection.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1441450173.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mextract_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/strawberry_leaf_dataset\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1350\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/images-of-strawberry-leaves-for-tipburn-detection.zip'"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "\n",
        "# Make sure kaggle.json is uploaded and in the right place\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download dataset to current directory (/content)\n",
        "!kaggle datasets download -d ercanavsar/images-of-strawberry-leaves-for-tipburn-detection\n",
        "\n",
        "# Extract it\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "dataset_path = \"/content/images-of-strawberry-leaves-for-tipburn-detection.zip\"\n",
        "extract_path = \"/content/strawberry_leaf_dataset\"\n",
        "\n",
        "with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"‚úÖ Dataset downloaded and extracted successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEmqpBaYcD2k"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Replace \"your_kaggle_username\" with your actual Kaggle username\n",
        "# Replace \"your_kaggle_key\" with the token you just got\n",
        "\n",
        "kaggle_json = {\n",
        "    \"username\": \"YOUR_KAGGLE_USERNAME\",\n",
        "    \"key\": \"KGAT_d21da844c4bcc4bbd26378876da2d8ab\"  # copy your token here\n",
        "}\n",
        "\n",
        "# Save it as kaggle.json\n",
        "with open(\"/content/kaggle.json\", \"w\") as f:\n",
        "    json.dump(kaggle_json, f)\n",
        "\n",
        "print(\"‚úÖ kaggle.json created successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePLr2lFfcIQ6"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwgw1hkzcL59"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "885UVEGwcUqn"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d ercanavsar/images-of-strawberry-leaves-for-tipburn-detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrCry8vMRB9G"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "dataset_path = \"images-of-strawberry-leaves-for-tipburn-detection.zip\"\n",
        "extract_path = \"strawberry_leaf_dataset\"\n",
        "\n",
        "with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Dataset extracted successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEuwfktcSBSV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "data_dir = \"strawberry_leaf_dataset\"  # Make sure this is the correct path\n",
        "\n",
        "for root, dirs, files in os.walk(data_dir):\n",
        "    print(f\"üìÇ Directory: {root}\")\n",
        "    for file in files[:5]:  # Print first 5 files in each folder\n",
        "        print(f\"  üìÑ {file}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gu36N82TAr0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Correct the base directory\n",
        "data_dir = \"strawberry_leaf_dataset/dataset - strawberry leaves\"\n",
        "\n",
        "# Check available subfolders (classes)\n",
        "categories = os.listdir(data_dir)\n",
        "print(\"Categories:\", categories)  # Should print [\"healthy\", \"Calciumdeficiency\"]\n",
        "\n",
        "# Select an image from the 'healthy' category\n",
        "sample_image_path = os.path.join(data_dir, \"healthy\", os.listdir(os.path.join(data_dir, \"healthy\"))[0])\n",
        "\n",
        "# Read and display the image\n",
        "sample_image = cv2.imread(sample_image_path)\n",
        "if sample_image is None:\n",
        "    print(\"‚ö†Ô∏è Error: Could not read the image file!\")\n",
        "else:\n",
        "    sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(sample_image)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8nywv2WTxAa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "\n",
        "def extract_features(image_path):\n",
        "    # Read and resize image\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (128, 128))  # Resize for consistency\n",
        "\n",
        "    # Convert to grayscale\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # --- 1. Color Histogram Features ---\n",
        "    hist_r = cv2.calcHist([img], [0], None, [256], [0, 256]).flatten()\n",
        "    hist_g = cv2.calcHist([img], [1], None, [256], [0, 256]).flatten()\n",
        "    hist_b = cv2.calcHist([img], [2], None, [256], [0, 256]).flatten()\n",
        "\n",
        "    # --- 2. Texture Features (GLCM) ---\n",
        "    glcm = graycomatrix(img_gray, distances=[1], angles=[0], symmetric=True, normed=True)\n",
        "    contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
        "    energy = graycoprops(glcm, 'energy')[0, 0]\n",
        "    homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
        "    correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
        "\n",
        "    # --- 3. Edge & Shape Features (Canny Edges) ---\n",
        "    edges = cv2.Canny(img_gray, 100, 200)  # Detect edges\n",
        "    edge_pixels = np.sum(edges) / (128 * 128)  # Edge density\n",
        "\n",
        "    # Combine all extracted features into one vector\n",
        "    features = np.hstack([hist_r, hist_g, hist_b, contrast, energy, homogeneity, correlation, edge_pixels])\n",
        "\n",
        "    return features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJbup40pTzDA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define dataset path\n",
        "data_dir = \"strawberry_leaf_dataset/dataset - strawberry leaves\"\n",
        "\n",
        "# Define classes (Healthy = 0, Tipburn/Deficiency = 1)\n",
        "labels = {\"healthy\": 0, \"Calciumdeficiency\": 1}\n",
        "\n",
        "X = []  # Feature matrix\n",
        "y = []  # Labels\n",
        "\n",
        "# Loop through both classes\n",
        "for category, label in labels.items():\n",
        "    folder_path = os.path.join(data_dir, category)\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        # Extract features\n",
        "        features = extract_features(img_path)\n",
        "        X.append(features)\n",
        "        y.append(label)\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Print dataset shape\n",
        "print(f\"Feature matrix shape: {X.shape}\")  # Should be (num_samples, num_features)\n",
        "print(f\"Labels shape: {y.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNqV0rHWVehX"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(X)\n",
        "df['label'] = y  # Add label column\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv(\"strawberry_leaf_features.csv\", index=False)\n",
        "print(\"‚úÖ Features saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wd3fyrNaWH6I"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvvX32EOWMLa"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"strawberry_leaf_features.csv\")\n",
        "\n",
        "# Separate features (X) and labels (y)\n",
        "X = df.drop(columns=[\"label\"]).values\n",
        "y = df[\"label\"].values\n",
        "\n",
        "# Split into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Normalize features (important for XGBoost)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "print(\"‚úÖ Data loaded and preprocessed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kevku7d7WOCD"
      },
      "outputs": [],
      "source": [
        "# Train Random Forest Model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Train XGBoost Model\n",
        "xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42, use_label_encoder=False, eval_metric=\"logloss\")\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"‚úÖ Models trained successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0goLfBvWVoZ"
      },
      "outputs": [],
      "source": [
        "# Get prediction probabilities from both models\n",
        "rf_probs = rf_model.predict_proba(X_test)\n",
        "xgb_probs = xgb_model.predict_proba(X_test)\n",
        "\n",
        "# Hybrid Model: Weighted Averaging (50% RF + 50% XGBoost)\n",
        "hybrid_probs = (0.5 * rf_probs) + (0.5 * xgb_probs)\n",
        "\n",
        "# Convert probabilities to final predictions\n",
        "hybrid_preds = np.argmax(hybrid_probs, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAI83nPWWYvO"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Compute Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, hybrid_preds)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Healthy\", \"Tipburn\"], yticklabels=[\"Healthy\", \"Tipburn\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix - Hybrid Model\")\n",
        "plt.show()\n",
        "\n",
        "# Print Classification Report\n",
        "print(\"üîπ Classification Report:\")\n",
        "print(classification_report(y_test, hybrid_preds))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KiaSdYtWePu"
      },
      "outputs": [],
      "source": [
        "# Accuracy Score\n",
        "accuracy = accuracy_score(y_test, hybrid_preds)\n",
        "print(f\"‚úÖ Model Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# F1-Score (More balanced than accuracy)\n",
        "from sklearn.metrics import f1_score\n",
        "f1 = f1_score(y_test, hybrid_preds)\n",
        "print(f\"‚úÖ Model F1-Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmlZ_yEKXPg1"
      },
      "outputs": [],
      "source": [
        "# Compute Accuracy\n",
        "accuracy = accuracy_score(y_test, hybrid_preds)\n",
        "print(f\"‚úÖ Model Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuufjGEUX3k6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ym1m0apX6le"
      },
      "outputs": [],
      "source": [
        "# Load extracted features from CSV\n",
        "df = pd.read_csv(\"strawberry_leaf_features.csv\")\n",
        "\n",
        "# Separate features (X) and labels (y)\n",
        "X = df.drop(columns=[\"label\"]).values\n",
        "y = df[\"label\"].values\n",
        "\n",
        "# Split into Training (80%) and Testing (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Normalize the dataset (important for XGBoost)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "print(\"‚úÖ Data Loaded & Preprocessed Successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWtTDZ-OX82c"
      },
      "outputs": [],
      "source": [
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "print(\"‚úÖ Random Forest Trained Successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBC4oOWFYAJC"
      },
      "outputs": [],
      "source": [
        "xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42, use_label_encoder=False, eval_metric=\"logloss\")\n",
        "xgb_model.fit(X_train, y_train)\n",
        "print(\"‚úÖ XGBoost Trained Successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWzWmAyxYD2K"
      },
      "outputs": [],
      "source": [
        "# Define the Hybrid Model using Voting Classifier\n",
        "hybrid_model = VotingClassifier(estimators=[\n",
        "    ('random_forest', rf_model),\n",
        "    ('xgboost', xgb_model)\n",
        "], voting='hard')  # Hard Voting (Majority Vote)\n",
        "\n",
        "# Train the Hybrid Model\n",
        "hybrid_model.fit(X_train, y_train)\n",
        "print(\"‚úÖ Hybrid Model (Voting Classifier) Trained Successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRHDNc0JYJ8K"
      },
      "outputs": [],
      "source": [
        "# Make Predictions\n",
        "y_pred = hybrid_model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXY2reLrYMWw"
      },
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"‚úÖ Hybrid Model Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byOMZ9fyYO5V"
      },
      "outputs": [],
      "source": [
        "print(\"üîπ Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDOFW04YYRJ8"
      },
      "outputs": [],
      "source": [
        "# Compute Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Healthy\", \"Tipburn\"], yticklabels=[\"Healthy\", \"Tipburn\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix - Hybrid Model\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKlkFLKmeEfn"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "rf_params = {\n",
        "    \"n_estimators\": [100, 200, 300],\n",
        "    \"max_depth\": [10, 20, 30, None],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"min_samples_leaf\": [1, 2, 4]\n",
        "}\n",
        "\n",
        "rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), rf_params, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
        "rf_grid.fit(X_train, y_train)\n",
        "\n",
        "best_rf = rf_grid.best_estimator_\n",
        "print(f\"‚úÖ Best RF Params: {rf_grid.best_params_}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVgWVQiZgVIm"
      },
      "outputs": [],
      "source": [
        "xgb_params = {\n",
        "    \"n_estimators\": [100, 200, 300],\n",
        "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
        "    \"max_depth\": [3, 5, 7],\n",
        "    \"subsample\": [0.8, 1.0]\n",
        "}\n",
        "\n",
        "xgb_grid = GridSearchCV(XGBClassifier(random_state=42, use_label_encoder=False, eval_metric=\"logloss\"),\n",
        "                        xgb_params, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
        "xgb_grid.fit(X_train, y_train)\n",
        "\n",
        "best_xgb = xgb_grid.best_estimator_\n",
        "print(f\"‚úÖ Best XGBoost Params: {xgb_grid.best_params_}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAyr4Ou6j7Qq"
      },
      "outputs": [],
      "source": [
        "optimized_hybrid = VotingClassifier(estimators=[\n",
        "    ('random_forest', best_rf),\n",
        "    ('xgboost', best_xgb)\n",
        "], voting='hard')\n",
        "\n",
        "optimized_hybrid.fit(X_train, y_train)\n",
        "y_pred_optimized = optimized_hybrid.predict(X_test)\n",
        "\n",
        "accuracy_optimized = accuracy_score(y_test, y_pred_optimized)\n",
        "print(f\"üöÄ Optimized Hybrid Model Accuracy: {accuracy_optimized:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKFI97wpkI8W"
      },
      "outputs": [],
      "source": [
        "soft_voting_model = VotingClassifier(estimators=[\n",
        "    ('random_forest', best_rf),\n",
        "    ('xgboost', best_xgb)\n",
        "], voting='soft')  # Change to 'soft'\n",
        "\n",
        "soft_voting_model.fit(X_train, y_train)\n",
        "y_pred_soft = soft_voting_model.predict(X_test)\n",
        "\n",
        "accuracy_soft = accuracy_score(y_test, y_pred_soft)\n",
        "print(f\"üöÄ Soft Voting Hybrid Model Accuracy: {accuracy_soft:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfH-TCqQkTka"
      },
      "outputs": [],
      "source": [
        "importances = best_rf.feature_importances_\n",
        "feature_names = df.drop(columns=[\"label\"]).columns\n",
        "\n",
        "# Select Top 10 Features\n",
        "important_features = pd.DataFrame({\"Feature\": feature_names, \"Importance\": importances})\n",
        "important_features = important_features.sort_values(by=\"Importance\", ascending=False).head(10)\n",
        "\n",
        "# Use only these top 10 features for training\n",
        "X_train_important = X_train[:, important_features.index]\n",
        "X_test_important = X_test[:, important_features.index]\n",
        "\n",
        "# Retrain the Hybrid Model with only important features\n",
        "optimized_hybrid.fit(X_train_important, y_train)\n",
        "y_pred_reduced = optimized_hybrid.predict(X_test_important)\n",
        "\n",
        "accuracy_reduced = accuracy_score(y_test, y_pred_reduced)\n",
        "print(f\"üöÄ Optimized Hybrid Model (Feature Selection) Accuracy: {accuracy_reduced:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OB28FgkNkY69"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import imgaug.augmenters as iaa\n",
        "import os\n",
        "\n",
        "augmenters = iaa.Sequential([\n",
        "    iaa.Fliplr(0.5),  # Horizontal Flip\n",
        "    iaa.Affine(rotate=(-20, 20)),  # Rotation\n",
        "    iaa.Multiply((0.8, 1.2))  # Brightness\n",
        "])\n",
        "\n",
        "def augment_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    augmented_image = augmenters.augment_image(image)\n",
        "    return augmented_image\n",
        "\n",
        "# Apply augmentation on training images and retrain the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ebZsuAmkoKl"
      },
      "outputs": [],
      "source": [
        "# Select the top 10 features from training\n",
        "X_test_important = X_test[:, important_features.index]\n",
        "\n",
        "# Now predict with the optimized model\n",
        "y_pred_optimized = optimized_hybrid.predict(X_test_important)\n",
        "accuracy_optimized = accuracy_score(y_test, y_pred_optimized)\n",
        "\n",
        "print(f\"üöÄ Optimized Hybrid Model Accuracy: {accuracy_optimized:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rP2bxR7xlRSZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=300,  # More trees = better learning (try 300-500)\n",
        "    max_depth=30,      # Increase depth (adjust based on performance)\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JzVwA10lWvh"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    n_estimators=500,      # More trees\n",
        "    learning_rate=0.05,    # Lower learning rate\n",
        "    max_depth=10,          # Deeper trees\n",
        "    subsample=0.8,         # Prevents overfitting\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8TYwYXClbI2"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "hybrid_model = VotingClassifier(\n",
        "    estimators=[('rf', rf_model), ('xgb', xgb_model)],\n",
        "    voting='soft',   # Use probability-based voting\n",
        "    weights=[1, 2]   # Give more weight to XGBoost (try tuning this)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MK-WegveleKQ"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Convert datasets into DMatrix (XGBoost's optimized data format)\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gByP_eqbmZh5"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    \"objective\": \"binary:logistic\",  # Since it's a classification problem\n",
        "    \"eval_metric\": \"logloss\",        # Log loss metric\n",
        "    \"max_depth\": 6,                  # Depth of trees\n",
        "    \"eta\": 0.05,                      # Learning rate\n",
        "    \"subsample\": 0.8,                 # Prevents overfitting\n",
        "    \"colsample_bytree\": 0.8\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkDVbWIzmcrl"
      },
      "outputs": [],
      "source": [
        "evals = [(dtest, \"eval\")]  # Validation dataset\n",
        "\n",
        "xgb_model = xgb.train(\n",
        "    params,               # Model parameters\n",
        "    dtrain,               # Training data\n",
        "    num_boost_round=500,  # Maximum boosting rounds\n",
        "    evals=evals,          # Validation set\n",
        "    early_stopping_rounds=50,  # Stops training if no improvement\n",
        "    verbose_eval=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NW3K5Wjxmq4P"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_preds = rf_model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-VyW8AimuNU"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "xgb_preds = xgb_model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmD8YExEm7zR"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "hybrid_model = VotingClassifier(\n",
        "    estimators=[(\"rf\", rf_model), (\"xgb\", xgb_model)],\n",
        "    voting=\"hard\"  # Majority vote\n",
        ")\n",
        "\n",
        "hybrid_model.fit(X_train, y_train)\n",
        "hybrid_preds = hybrid_model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqNhJ9gbnGv3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "hybrid_accuracy = accuracy_score(y_test, hybrid_preds)\n",
        "print(f\"‚úÖ Hybrid Model Accuracy: {hybrid_accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, hybrid_preds))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, hybrid_preds))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DALOW9JZjoS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"strawberry_leaf_features.csv\")\n",
        "\n",
        "# Separate features and labels\n",
        "X = df.drop(columns=[\"label\"]).values\n",
        "y = df[\"label\"].values\n",
        "\n",
        "# Train a Random Forest model to get feature importance\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X, y)\n",
        "\n",
        "# Get the top 20 important features\n",
        "importances = rf.feature_importances_\n",
        "indices = np.argsort(importances)[-20:]  # Select top 20\n",
        "X_selected = X[:, indices]\n",
        "\n",
        "# Update dataset with selected features\n",
        "df_selected = pd.DataFrame(X_selected)\n",
        "df_selected['label'] = y\n",
        "\n",
        "# Save the new dataset\n",
        "df_selected.to_csv(\"strawberry_leaf_selected_features.csv\", index=False)\n",
        "\n",
        "print(\"‚úÖ Feature selection done! Dataset updated with important features.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Dk87oInZpcp"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define parameter grid\n",
        "rf_params = {\n",
        "    \"n_estimators\": [200, 300, 400],\n",
        "    \"max_depth\": [10, 20, 30],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"min_samples_leaf\": [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Perform Grid Search\n",
        "rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), rf_params, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
        "rf_grid.fit(X_selected, y)\n",
        "\n",
        "# Get the best model\n",
        "best_rf = rf_grid.best_estimator_\n",
        "print(f\"‚úÖ Best RF Params: {rf_grid.best_params_}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGEl1grmkOvX"
      },
      "outputs": [],
      "source": [
        "!pip install optuna\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJhWLgcpaeSP"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500, step=50),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0)\n",
        "    }\n",
        "    model = xgb.XGBClassifier(**params, random_state=42)\n",
        "    score = cross_val_score(model, X_selected, y, cv=3, scoring=\"accuracy\").mean()\n",
        "    return score\n",
        "\n",
        "# Run optimization\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "# Get best parameters\n",
        "best_xgb_params = study.best_params\n",
        "print(f\"‚úÖ Best XGBoost Params: {best_xgb_params}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1EkyGiJa2FM"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import imgaug.augmenters as iaa\n",
        "import os\n",
        "\n",
        "augmenters = iaa.Sequential([\n",
        "    iaa.Fliplr(0.5),\n",
        "    iaa.Affine(rotate=(-20, 20)),\n",
        "    iaa.Multiply((0.8, 1.2))\n",
        "])\n",
        "\n",
        "def augment_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    augmented_image = augmenters.augment_image(image)\n",
        "    return augmented_image\n",
        "\n",
        "print(\"‚úÖ Data augmentation applied!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swhh1-xDa3vv"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# Train an Isolation Forest to detect outliers\n",
        "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
        "outliers = iso_forest.fit_predict(X_selected)\n",
        "\n",
        "# Keep only normal data points\n",
        "X_clean = X_selected[outliers == 1]\n",
        "y_clean = y[outliers == 1]\n",
        "\n",
        "print(f\"‚úÖ Outliers removed! New dataset size: {X_clean.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48mMKUsna7Gl"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Define the hybrid model with optimized parameters\n",
        "optimized_hybrid = VotingClassifier(\n",
        "    estimators=[('random_forest', best_rf), ('xgboost', xgb.XGBClassifier(**best_xgb_params))],\n",
        "    voting='soft',\n",
        "    weights=[1, 2]  # Give more weight to XGBoost\n",
        ")\n",
        "\n",
        "# Train and evaluate\n",
        "optimized_hybrid.fit(X_clean, y_clean)\n",
        "y_pred = optimized_hybrid.predict(X_clean)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_optimized = accuracy_score(y_clean, y_pred)\n",
        "print(f\"üöÄ Optimized Hybrid Model Accuracy: {accuracy_optimized:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5Ql27NhlF--"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = hybrid_model.predict(X_test)\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Classification report (includes F1-score, precision, recall)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiBahOzolvIb"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Healthy', 'Tipburn'], yticklabels=['Healthy', 'Tipburn'])\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llbhw2h3WATX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "# For ROC, we need predicted probabilities instead of class labels\n",
        "# If your hybrid model is a VotingClassifier with 'soft' voting, use predict_proba\n",
        "# Otherwise, we'll need to modify for individual models\n",
        "\n",
        "# Check if hybrid model supports predict_proba\n",
        "if hasattr(optimized_hybrid, \"predict_proba\"):\n",
        "    y_probs = optimized_hybrid.predict_proba(X_test)[:, 1]  # Probability of positive class (Tipburn)\n",
        "else:\n",
        "    # If not, fallback to XGBoost probabilities as proxy\n",
        "    y_probs = xgb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
        "\n",
        "# Compute AUC\n",
        "auc_score = roc_auc_score(y_test, y_probs)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {auc_score:.4f})')\n",
        "plt.plot([0,1], [0,1], color='red', linestyle='--', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve - Hybrid Model')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}